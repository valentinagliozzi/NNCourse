{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valentinagliozzi/NNCourse/blob/main/LabCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUtPyseJqqlC"
      },
      "source": [
        "# **Convolutional Neural Networks** (CNNs)\n",
        "\n",
        "\n",
        "\n",
        "Le [reti convoluzionali](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN) sono un tipo di rete neurale artificiale progettata per l'elaborazione efficiente di dati in forma matriciale (o tensoriale), tra cui le immagini sono l'esempio pi√π comune.\n",
        "\n",
        "Queste reti hanno rivoluzionato il campo dell'elaborazione di immagini, e hanno sancito il diffonfersi del deep learning. In molti problemi, tra cui analisi di immagini, riconoscimento di pattern e visione artificiale, il deep learning costituisce lo stato dell'arte da circa 10 anni.\n",
        "\n",
        "Le CNN utilizzano layer convoluzionali (cio√® layer che effettuano la [convoluzione discreta](https://en.wikipedia.org/wiki/Convolution#Discrete_convolution)) per l'estrazione di features e layer fully connected, insieme per la risoluzione del task in esame (nel nostro caso, *classificazione multi-classe*).\n",
        "\n",
        "![Immagine](https://mriquestions.com/uploads/3/4/5/7/34572113/cnn-sample-layout_orig.png)\n",
        "\n",
        "Le CNNs sono complesse rispetto ai Multilayer Perceptron, perci√≤ pu√≤ non essere banale visualizzarne la struttura. Tuttavia, sul web sono state create delle ottime visualizzazioni, come \"[An Interactive Node-Link Visualization of Convolutional Neural Networks](https://adamharley.com/nn_vis/)\" di Adam W. Harley.\n",
        "\n",
        "![Screenshot interactive node visualization](https://adamharley.com/nn_vis/images/convnet_flat_480.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DbXKIib3T0z"
      },
      "source": [
        "---\n",
        "\n",
        "# üß™‚öóÔ∏è <font color='lime'><u>**Laboratorio: classificazione di FashionMNIST con CNN**</u></font>\n",
        "\n",
        "Utilizziamo [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), un dataset contenente immagini a bassa risoluzione di capi di abbigliamento, fornito da Zalando per la classificazione. E' stato pensato come benchmark pi√π difficile di [MNIST](https://en.wikipedia.org/wiki/MNIST_database), noto dataset contenente un ampio insieme di immagini di cifre scritte a mano.\n",
        "\n",
        "Come framework per il Deep Learning utilizzeremo **PyTorch**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyvZ9kAN5iLa"
      },
      "source": [
        "### <font color='gold'>**Installazione dipendenze e importazione librerie**</font>\n",
        "\n",
        "Installiamo le dipendenze e importiamo le librerie necessarie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMga4dM6AVHs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install umap-learn torchviz torchview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy7uKoVRrvVG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# per visualizzazione dati\n",
        "from sklearn.decomposition import PCA\n",
        "from umap import UMAP\n",
        "\n",
        "# per visualizzare grafici\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# componenti PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# varie\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from types import SimpleNamespace\n",
        "from torchviz import make_dot\n",
        "from torchview import draw_graph\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XEaQOEy6KmE"
      },
      "source": [
        "### <font color='gold'>**Creazione del dataset**</font>\n",
        "\n",
        "PyTorch fornisce la classe `FashionMNIST` (`torchvision.datasets`) che racchiude il dataset sotto forma di lista di [PIL images](https://pillow.readthedocs.io/en/latest/reference/Image.html). Per convertirle in tensori, √® sufficiente specificare l'uso della trasformazione `torchvision.ToTensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Y3NBnDs3_p"
      },
      "outputs": [],
      "source": [
        "dataset = FashionMNIST(\n",
        "    root='data',  # directory per download\n",
        "    download=True,\n",
        "    transform=ToTensor()  # trasformazione: PIL.image ==> torch.Tensor\n",
        "    )\n",
        "target_names =  ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print('\\nInformazioni sul dataset\\n' + '-'*100)\n",
        "print(f'Numero di esempi: {len(dataset):,}')\n",
        "print('Numero di classi:', len(set(dataset.targets.tolist())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk0LJOyt6tpp"
      },
      "source": [
        "### <font color='gold'>**Partizionamento del dataset: train, validation, test**</font>\n",
        "\n",
        "Usando la funzione `torch.utils.data.random_split` dividiamo randomicamente il dataset in 3 porzioni:\n",
        "\n",
        "- <u>Training set</u> (80%): contiene i dati che saranno usati per trainare la rete\n",
        "- <u>Test set</u> (10%): contiene i dati che saranno usato **soltanto alla fine**, per testare le performance della rete\n",
        "- <u>Validation set</u> (10%): contiene i dati che saranno usati periodicamente durante il training per stimare la performance che la rete ha sul test set.\n",
        "\n",
        "‚û°Ô∏è **Nota bene**: i dati presenti nel validation set non sono usati per trainare la rete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLFr9xHN29dT"
      },
      "outputs": [],
      "source": [
        "seed_random_split = 2023\n",
        "\n",
        "random_generator = torch.Generator().manual_seed(seed_random_split)\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, lengths=[0.8, 0.1, 0.1], generator=random_generator)\n",
        "\n",
        "print('Random split dataset\\n' + '-'*100)\n",
        "print(f'Training set:\\t{len(train_dataset):,}')\n",
        "print(f'Validation set:\\t{len(val_dataset):,}')\n",
        "print(f'Test set:\\t{len(test_dataset):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-uWG8d7yYm"
      },
      "source": [
        "###   <font color='gold'>**Osserviamo qualche informazione di un esempio del training set**</font>\n",
        "\n",
        "Possiamo vedere che un esempio √® un tensore a 3 dimensioni, riferite rispettivamente a:\n",
        "\n",
        "1. numero di canali:\n",
        "  - immagini RGB avranno 3 canali\n",
        "  - immagini RGBA (A = alpha, opacit√†) avranno 4 canali\n",
        "  - immagini grayscale (<u>il nostro caso</u>) 1 solo canale\n",
        "2. altezza dell'immagine\n",
        "3. larghezza dell'immagine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9vGxOiBziL_"
      },
      "outputs": [],
      "source": [
        "print('Esempio numero 1\\n' + '-'*100)\n",
        "x, y = train_dataset[0]\n",
        "print('Input:', x.shape, '\\t ==> (channel, height, width)')\n",
        "print('Classe:', y, f'({target_names[y]})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0mjmvCg8ILf"
      },
      "source": [
        "### <font color='gold'>**Visualizziamo alcuni esempi (immagini)**</font>\n",
        "\n",
        "Possiamo usare la funzione `matplotlib.pyplot.imshow` per visualizzare i tensori sotto forma di immagine. La funzione mappa ogni valore (normalizzato sul range [0,1]) ad un colore. In questo caso invertiamo il valore per avere delle immagini nere su sfondo bianco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWg7TIOAx4Pp"
      },
      "outputs": [],
      "source": [
        "plt.subplots(4,4, figsize=(10,10))\n",
        "for i in range(16):\n",
        "  x, y = train_dataset[i]\n",
        "  plt.subplot(4, 4, i+1)\n",
        "  plt.imshow(1-x[0], cmap='gray')\n",
        "  plt.title(target_names[y])\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a2OtcHA8rvi"
      },
      "source": [
        "### <font color='gold'>**Visualizziamo la distribuzione degli esempi (w/ dimensionality reduction)**</font>\n",
        "\n",
        "Quando si deve risolvere un task √® buona norma prima osservare attentamente il dataset.\n",
        "\n",
        "Possiamo visualizzare quanto sono separate le classi proiettando i tensori degli esempi in uno spazio bidimensionale e visualizzandoli in uno *scatter plot*.\n",
        "\n",
        "Possiamo ridurre i tensori corrispondenti agli esempi in coppie di numeri reali usando un approccio di *dimensionality reduction*."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo una *utility function* che ci permetta di visualizzare il dataset usando un dato metodo di dimensionality reduction (che sia conforme con l'interfaccia di `Scikit-Learn`)"
      ],
      "metadata": {
        "id": "Eq1uY259itV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5fkG8va33d1"
      },
      "outputs": [],
      "source": [
        "def plot_dataset_visualization(X, y, method, title):\n",
        "  X_transformed = method.fit_transform(X)\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  for i, l in enumerate(target_names):\n",
        "    X_plot = X_transformed[y == i]\n",
        "    plt.scatter(X_plot[:,0], X_plot[:,1], label=l, c=f'C{i}', s=1)\n",
        "\n",
        "  plt.legend(markerscale=8, loc=(1.01,0), frameon=False)\n",
        "  plt.title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_wZMdaq89f3"
      },
      "source": [
        "Visualizziamo il dataset, colorando gli esempi della stessa classe con lo stesso colore, usando 2 metodi diversi di visualizzazione:\n",
        "\n",
        "- [Principal Component Analisys](https://it.wikipedia.org/wiki/Analisi_delle_componenti_principali) (PCA). Con la PCA si effettua una trasformazione lineare del dataset in uno spazio di nuove features non correlate tra loro. Successivamente, si mantengono le *n* (2 nel nostro caso) features che catturano la massima varianza.\n",
        "\n",
        "- [Uniform manifold approximation and projection](https://pair-code.github.io/understanding-umap/) (UMAP): Metodo di riduzione della dimensionalit√† non lineare che produce un risultato simile alla PCA, ma permette di visualizzare in maniera molto chiara la separazione tra classi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgX0zPAK5GER"
      },
      "outputs": [],
      "source": [
        "X = dataset.data\n",
        "y = dataset.targets\n",
        "X = X.reshape(len(X), -1)\n",
        "\n",
        "\n",
        "visualizers = {\n",
        "    'Principal Component Analysis': PCA(n_components=2),\n",
        "    'Uniform Manifold Approximation and Projection': UMAP(n_components=2, n_epochs=50)\n",
        "}\n",
        "\n",
        "for name, method in visualizers.items():\n",
        "  plot_dataset_visualization(X, y, method, name)\n",
        "  plt.show()\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XGHLTdf3T02"
      },
      "source": [
        "Possiamo osservare che le classi sono parzialmente sovrapposte, rendendo il problema di classificazion non banale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnMgDGKiCTft"
      },
      "source": [
        "### <font color='gold'>**Definizione della rete convoluzionale**</font>\n",
        "\n",
        "In `PyTorch` per definire una rete, √® necessario:\n",
        "\n",
        "- estendere la classe `torch.nn.Module`\n",
        "- definire i layer (o eventualmente i singoli parametri) della rete nella funzione `__init__`\n",
        "- implementare la funzione `forward` che costituisce la passata in avanti della rete"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo la rete convoluzionale usando layer offerti da PyTorch:\n",
        "\n",
        "- `Conv2d` ci permette di definire convoluzioni, specificando canali di input/output, dimensione del kernel, stride, padding\n",
        "- funzione di attivazione `ReLU`\n",
        "- `MaxPool2d` specificando dimensione del kernel, stride, padding\n",
        "- `BatchNorm2d` *normalizza* e *centra* l'input del layer. Stabilizza e accelera il training\n",
        "- `Dropout` azzera alcune features dell'input del layer con probabilit√† $p$ (soltanto durante il training). Migliora la generalizzazione della rete.\n",
        "\n",
        "Nella parte restante della rete utilizziamo anche:\n",
        "\n",
        "- `Linear`, che definisce un singolo layer fully connected\n",
        "- come livello finale `Softmax`, che calcola la probabilit√† di appartenenza alla $i$-esima classe come segue:\n",
        "\n",
        "$$\\text{softmax}(\\mathbf{x})_i = \\frac{\\exp\\left(x_i\\right)}{\\exp\\left(\\sum_{j=1}^d x_j\\right)}$$"
      ],
      "metadata": {
        "id": "321JQ7VjqsEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_uWqNk3aYPs"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding='valid'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='valid'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Dropout(0.6), # 0.6\n",
        "        nn.Linear(in_features=800, out_features=256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=256, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "    self.out = nn.Sequential(\n",
        "        nn.Linear(in_features=64, out_features=len(target_names)),\n",
        "        nn.Softmax(-1)\n",
        "    )\n",
        "    self.embeddings = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "\n",
        "    # appiattisci dalla dimensione 1 in poi\n",
        "    x = x.flatten(1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    # salviamo la rappresentazione vettoriale per la visualizzazione\n",
        "    self.embeddings = x\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "print('Architettura della rete convoluzionale\\n' + '-' * 100)\n",
        "model = CNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97AibjK73T03"
      },
      "source": [
        "### üí°<font color='lightblue'>**Approfondimento: visualizzazione con GraphViz del modello e del grafo computazionale**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB65HfmR3T03"
      },
      "source": [
        "Esistono delle librerie per visualizzare l'architettura sotto forma di grafo. Ad esempio la funzione `torchview.draw_graph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xi6jRka3T03"
      },
      "outputs": [],
      "source": [
        "x = torch.zeros(10, 1, 28, 28)\n",
        "y = torch.zeros(10)\n",
        "dot = draw_graph(model, input_data=x, expand_nested=True, graph_name='CNN', device='cpu')\n",
        "dot.resize_graph(1.5)\n",
        "dot.visual_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fct2SW-o3T03"
      },
      "source": [
        "Altre librerie, come `torchviz`, ci permettono di visualizzare l'intero grafo computazionale. Ad esempio, calcoliamo l'output del modello e visualizziamo il grafo con la funzione `torchviz.make_dot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57wEkdnt3T03"
      },
      "outputs": [],
      "source": [
        "pred = model(x)\n",
        "dot = make_dot(pred, params=dict(list(model.named_parameters()) + [('Prediction', pred)]))\n",
        "dot.node_attr.update({'width': '0.1', 'margin': '0.01'})\n",
        "dot.graph_attr.update({'size': '50,50', 'nodesep': '0.2', 'ranksep': '0.25'})\n",
        "dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw8Cro-7C8fA"
      },
      "source": [
        "### <font color='gold'>**Funzione `evaluate`**</font>\n",
        "\n",
        "Definiamo una *utility function* per valutare le performance di un modello su un dataset.\n",
        "La funzione restituisce:\n",
        "\n",
        "- <u>loss media</u> sul dataset\n",
        "- <u>accuratezza</u> della predizione (assumendo che si selezioni la classe con probabilit√† massima)\n",
        "- <u>info</u>: dizionario che contiene dei dati che ci serviranno per studiare il training\n",
        "    - embedding (rappresentazione vettoriale prima del livello di output) degli esempi\n",
        "    - distribuzione di probabilit√† restituita dal modello\n",
        "    - predizione del modello (classe pi√π probabile)\n",
        "    - targets (true labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O06CHdlULayW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataset, args, no_loading_bar=True):\n",
        "  dataloader = DataLoader(dataset, batch_size=args.batch_size, num_workers=2)\n",
        "\n",
        "  tot_loss = 0\n",
        "  n_correct = 0\n",
        "  embeddings, preds, target, probs = [], [], [], []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for (X, y) in tqdm(dataloader, disable=no_loading_bar):\n",
        "      X, y = X.to(args.device), y.to(args.device)\n",
        "\n",
        "      # calcolo delle probabilit√† di appartenenza alle classi\n",
        "      prob = model(X)\n",
        "\n",
        "      # calcolo delle predizioni: classe con probabilit√† massima\n",
        "      pred = prob.argmax(-1)\n",
        "\n",
        "      # calcolo della loss media sul batch (pu√≤ esserre Mean-Squared Error, Cross Entropy, o altro...)\n",
        "      loss = args.loss_fn(prob, y)\n",
        "\n",
        "      n_correct += sum(pred == y)\n",
        "      tot_loss += loss.item() * X.shape[0]\n",
        "\n",
        "      embeddings.append(model.embeddings)\n",
        "      probs.append(prob)\n",
        "      preds.append(pred)\n",
        "      target.append(y)\n",
        "\n",
        "  info = {\n",
        "    'embeddings': torch.cat(embeddings),\n",
        "    'prob': torch.cat(probs),\n",
        "    'preds': torch.cat(preds),\n",
        "    'target': torch.cat(target)\n",
        "  }\n",
        "  return tot_loss / len(dataset), n_correct / len(dataset), info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB1TPaIbDjk4"
      },
      "source": [
        "### <font color='gold'>**Funzione `train`**</font>\n",
        "\n",
        "Definiamo la vera e propria funzione di training. La funzione implementa un algoritmo di [Early stopping](https://en.wikipedia.org/wiki/Early_stopping), tecnica di regolarizzazione che permette di trainare un modello per evitare l'overfitting. Questo algoritmo si basa sul concetto di *pazienza*, cio√® il numero di epoche che possono trascorrere senza che la validation loss diminuisca prima che il training termini.\n",
        "\n",
        "Detto in altri termini, l'early stopping funziona come segue:\n",
        "\n",
        "1. considera un parametro `patience`, e una variabile `count` (inizialmente pari a 0)\n",
        "2. al termine di ogni epoca, calcola la validation loss\n",
        "3. se la validation loss √® <font color='green'>minore</font> di quella all'epoca precedente, continua il training per l'epoca successiva\n",
        "4. altirmenti, se la loss √® <font color='red'>maggiore</font> dell'epoca aggiorna count come segue: `count = count + 1`\n",
        "5. se `count == patience` (√® stato raggiunto il livello di *pazienza*), allora termina il training\n",
        "\n",
        "**Nota 1:** <font color=\"aqua\">perch√© usare la pazienza, e non interrompere quando la validation loss scende?</font>\n",
        "- <u>si ha overfitting</u> quando la training loss continua a scendere ma la validation loss inizia a salire\n",
        "- tuttavia, pu√≤ non essere una buona idea arrestare il training appena si incontra una validation loss minore rispetto all'epoca precedente\n",
        "- infatti, capita spesso che in una qualche epoca successiva, la loss diminuisca nuovamente\n",
        "\n",
        "**Nota 2:** <font color='aqua'>tenere traccia del checkpoint (stato dei pesi della rete) migliore</font>\n",
        "- √® buona norma mantenere traccia dei pesi della rete ogniqualvolta la validation loss migliora\n",
        "- in questo modo, alla fine del training possiamo ottenere la rete con la <u>minima validation loss</u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwfJlCg0LZ9H"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataset, val_dataset, args):\n",
        "  optimizer = args.optim_class(model.parameters(), lr=args.lr)\n",
        "  dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  train_losses, val_losses = dict(), dict()\n",
        "  step = -1\n",
        "  count = 0\n",
        "  best_val_loss = float('inf')\n",
        "  best_model = None\n",
        "\n",
        "  ### INIZIO TRAINING\n",
        "  for epoch in range(args.n_epochs):\n",
        "\n",
        "    tot_loss = 0\n",
        "    num_examples = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    loading_bar = tqdm(dataloader)\n",
        "    model.train()\n",
        "\n",
        "    ### EPOCA DI TRAINING\n",
        "    for (X, y) in loading_bar:\n",
        "      X, y = X.to(args.device), y.to(args.device)\n",
        "\n",
        "      # probabilit√† classi\n",
        "      prob = model(X)\n",
        "\n",
        "      # media loss sul batch\n",
        "      loss = args.loss_fn(prob, y)\n",
        "\n",
        "      # azzeramento gradiente, backprop, e ottimizzazione\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      step += 1\n",
        "\n",
        "      # log step\n",
        "      tot_loss += loss.item() * X.shape[0]\n",
        "      num_examples += X.shape[0]\n",
        "      running_loss = tot_loss / num_examples\n",
        "      train_losses[step] = running_loss\n",
        "\n",
        "      pred = prob.argmax(-1)\n",
        "      n_correct += sum(pred == y)\n",
        "\n",
        "      loading_bar.set_description(f'Epoch {epoch+1:<3d} [Loss: {running_loss:.4f}]')\n",
        "    ### FINE EPOCA DI TRANING\n",
        "\n",
        "    train_accuracy = n_correct / len(train_dataset)\n",
        "    val_loss, val_accuracy, _ = evaluate(model, val_dataset, args)\n",
        "    val_losses[step] = val_loss\n",
        "\n",
        "    print('-'*80)\n",
        "    print(f'Train accuracy: {train_accuracy:.2%}')\n",
        "    print(f'Val accuracy:   {val_accuracy:.2%}')\n",
        "    print(f'Val loss:       {val_loss:.4f}')\n",
        "\n",
        "    # early stopping\n",
        "    if val_loss > best_val_loss:\n",
        "      count += 1\n",
        "      print(f'===> Patience {count:>3d}/{args.patience:<3d}')\n",
        "      if count == args.patience:\n",
        "        break\n",
        "    else:\n",
        "      count = 0\n",
        "      best_val_loss = val_loss\n",
        "      best_model = model.state_dict()\n",
        "\n",
        "    print()\n",
        "  ### FINE TRAINING\n",
        "\n",
        "  model.load_state_dict(best_model)\n",
        "\n",
        "  return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCwOcTzk3T04"
      },
      "source": [
        "### <font color='gold'>**Definizione degli iperparametri di training**</font>\n",
        "\n",
        "Definiamo gli iperparametri di training. Usiamo la **Cross-Entropy Loss**, spesso migliore del *Mean-Squared Error* nei problemi di classificazione:\n",
        "\n",
        "$$\n",
        "H_p(q) = - \\sum_{c=1}^Cq(y_c) \\log p(y_c)\n",
        "$$\n",
        "\n",
        "Come algoritmo di ottimizzazione usiamo *Adam*, spesso migliore del classico *Stochastic Gradient Descent*.\n",
        "\n",
        "Salviamo i pesi della rete per eseguire dei confronti con quelli al termine del training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w_IRj2_-2H8"
      },
      "outputs": [],
      "source": [
        "args = SimpleNamespace(\n",
        "    loss_fn = nn.CrossEntropyLoss(),\n",
        "    optim_class = torch.optim.Adam,\n",
        "    batch_size = 1024,\n",
        "    lr = 0.0005,\n",
        "    n_epochs = 20,\n",
        "    patience = 20,\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "model = CNN().to(args.device)\n",
        "\n",
        "torch.save(model.state_dict(), 'model_before_train.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grVW6mEB3T04"
      },
      "source": [
        "### <font color='gold'>**Training!**</font> üß†\n",
        "\n",
        "Siamo pronti per trainare la rete. <u>**Nota:**</u> su **Colab con runtime T4 GPU** il training impiega circa <font color='red'>2</font> minuti.\n",
        "\n",
        "Salviamo i pesi del modello dopo il training e training e validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAO12UJKuS_D"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = train(model, train_dataset, val_dataset, args)\n",
        "\n",
        "torch.save({'train': train_losses, 'val': val_losses}, 'losses.pt')\n",
        "torch.save(model.state_dict(), 'model_after_train.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhxiLE7-3T04"
      },
      "source": [
        "### üí°<font color='lightblue'>**Approfondimento: visualizzazione delle rappresentazioni apprese dalla rete**</font>\n",
        "\n",
        "Possiamo visualizzare come la rete ha imparato a rappresentare al suo interno ciascun esempio.\n",
        "\n",
        "Nel definire la funzione `forward` della rete, abbiamo programmato il salvataggio della rappresentazione interna della rete prima del livello di output, come mostrato qui:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eZaZp8k3T04"
      },
      "outputs": [],
      "source": [
        "print(model.__repr__().replace('(out)', '\\033[96m>>>>>>>>>>>>>>> SALVIAMO QUI GLI EMBEDDINGS (INPUT DEL LIVELLO DI OUTPUT) <<<<<<<<<<<<<<<\\033[0m\\n  (out)'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D4z0gmF3T05"
      },
      "source": [
        "Visualizziamo con la PCA le rappresentazioni vettoriali di ciascun esempio prese prima della porzione della rete chiamata `out` (che ci restituisce le probabilit√† di appartenenza ad una classe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUTpLelrwMPu"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('model_before_train.pt'))\n",
        "_, _, info = evaluate(model, train_dataset, args, no_loading_bar=False)\n",
        "plot_dataset_visualization(info['embeddings'].cpu(), info['target'].cpu(), PCA(2), 'Rappresentazione interna prima del training')\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "model.load_state_dict(torch.load('model_after_train.pt'))\n",
        "_, _, info = evaluate(model, train_dataset, args, no_loading_bar=False)\n",
        "plot_dataset_visualization(info['embeddings'].cpu(), info['target'].cpu(), PCA(2), 'Rappresentazione interna $\\mathbf{dopo}$ il training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkdHIH-NF1R7"
      },
      "source": [
        "### <font color='gold'>**Visualizzazione training loss e validation loss**</font>\n",
        "\n",
        "Ora possiamo visualizzare il grafico delle training loss e validation loss. Sovrapponiamo le due curve in modo da vedere come progrediscono durante il trainig. Visualizziamo anche le curve in scala logarimica (sul numero di *step*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUL5108sp5en"
      },
      "outputs": [],
      "source": [
        "losses_dict = torch.load('losses.pt')\n",
        "train_losses, val_losses = losses_dict['train'], losses_dict['val']\n",
        "\n",
        "plt.subplots(1,2, figsize=(16,4))\n",
        "for i, (func, title) in enumerate([(plt.plot, 'Loss'), (plt.semilogx, 'Loss (log scale)')]):\n",
        "  plt.subplot(1,2,i+1)\n",
        "  func(list(train_losses.keys()), list(train_losses.values()), label='Train loss')\n",
        "  func(list(val_losses.keys()), list(val_losses.values()), label='Val loss')\n",
        "  idx = np.argmin(list(val_losses.values()))\n",
        "  plt.axvline(list(val_losses.keys())[idx], color='red', label='Best val loss', linestyle='dashed')\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  plt.subplots_adjust(wspace=0.1)\n",
        "  plt.xlabel('step')\n",
        "  plt.grid('on', 'both')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qvvku_FF8Kb"
      },
      "source": [
        "### <font color='gold'>**Testing del modello**</font>\n",
        "\n",
        "Terminato il training, possiamo testare le performance del nostro modello. In primis, calcoliamo l'accuratezza delle predizioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btjy3n3EsJFy"
      },
      "outputs": [],
      "source": [
        "_, test_accuracy, info = evaluate(model, test_dataset, args)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qFxeeXS3T1A"
      },
      "source": [
        "Ora visualizziamo la matrice di confusione, in modo da osservare gli errori pi√π comuni effettuati dal modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgZge2l33T1A"
      },
      "outputs": [],
      "source": [
        "target, preds = info['target'].cpu(), info['preds'].cpu()\n",
        "ConfusionMatrixDisplay.from_predictions(target, preds)\n",
        "plt.gca().set_yticklabels(target_names)\n",
        "plt.gca().set_xticklabels(target_names)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdJDLf_3T1A"
      },
      "source": [
        "### üí°<font color='lightblue'>**Approfondimento: classificazione scorretta di *Shirts***</font>\n",
        "\n",
        "Si pu√≤ osservare che gli esempi della classe *Shirt* sono spesso classificati erroneamente."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentuale di esempi con classificazione errata\\n' + '-'*100)\n",
        "for y in range(len(target_names)):\n",
        "  misclassified_y = (preds != target) & (target == y)\n",
        "  all_y = target == y\n",
        "\n",
        "  print(f'{target_names[y]:>12}: {sum(misclassified_y)/sum(all_y):.2%}')"
      ],
      "metadata": {
        "id": "hu2gKCqzuv0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se siamo curiosi, possiamo andare a vedere le *Shirt* classificate in maniera errata, e possiamo ispezionare le probabilit√† di ciascuna classe."
      ],
      "metadata": {
        "id": "eQ5Cc3FhuuqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivSsjTF3T1A"
      },
      "outputs": [],
      "source": [
        "# filtiramo le \"shirt\" del test set che non sono state classificate correttamente\n",
        "misclassified_shirts = (preds != target) & (target == 6)\n",
        "indexes = misclassified_shirts.nonzero().flatten()\n",
        "probs = info['prob'].cpu()[misclassified_shirts]\n",
        "\n",
        "# griglia 4 x 3\n",
        "rows, cols = 4, 3\n",
        "fig, _ = plt.subplots(rows, 2 * cols, figsize=(12,10))\n",
        "fig.suptitle(f'Predizioni del modello (true class: {target_names[6]})', y=0.9)\n",
        "\n",
        "for i in range(0, rows * cols * 2, 2):\n",
        "    plt.subplot(rows, 2 * cols, i+1)\n",
        "    x, y = test_dataset[indexes[i]]\n",
        "    plt.imshow(1-x[0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(rows, 2 * cols, i+2)\n",
        "    # stampiamo un diagramma a torta delle probabilit√† superiori allo 0.01%\n",
        "    probs_i = np.round(100 * probs[i].numpy(), decimals=2)\n",
        "    patches, _ = plt.pie(probs_i)\n",
        "    patches = [patches[i] for i, p in enumerate(probs_i) if p >= 0.01]\n",
        "    labels = [f'{target_names[i]} - {p:.2f}%' for i, p in enumerate(probs_i) if p >= 0.01]\n",
        "    plt.legend(patches, labels, loc='upper center', fontsize=8, framealpha=0.5)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.01, hspace=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusione\n",
        "\n",
        "Risolvere un problema di Machine Learning richiede quasi sempre *trial and error*, soprattutto nella scelta degli iperparametri.\n",
        "\n",
        "I curiosi possono provare a migliorare le performance del modello. <font color='gold'><u>**Cosa modificare?**</u></font>\n",
        "\n",
        "1) Aiutandosi con la [documentazione di Pytorch](https://pytorch.org/docs/stable/nn.html), provare a variare nel modello:\n",
        "* il numero di layer convoluzionali\n",
        "* parametri dei layer convoluzionali e di pooling\n",
        "  * kernel size\n",
        "  * padding\n",
        "  * stride\n",
        "* il numero di strati *fully connected* (`Linear`) e, in ognuno, il numero di neuroni\n",
        "* la presenza di strati `Dropout` (eventualmente modificando il *dropout rate*)\n",
        "* la presenza di strati `BatchNorm2d`\n",
        "\n",
        "2) Variare gli iperparametri di apprendimento:\n",
        "* il numero massimo di epoche\n",
        "* il numero di epoche in cui \"pazientare\"\n",
        "* la dimensione dei mini-batch\n",
        "* l'algoritmo di apprendimento (es. `SGD`)\n",
        "* learning rate\n",
        "\n",
        "**Con questo dataset e usando una rete convoluzionale relativamente semplice, l'accuracy potr√† superare senza problemi il 90%.**"
      ],
      "metadata": {
        "id": "CtXsP7a-DJpL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uyvZ9kAN5iLa",
        "6XEaQOEy6KmE",
        "dk0LJOyt6tpp",
        "O9-uWG8d7yYm",
        "p0mjmvCg8ILf",
        "5a2OtcHA8rvi",
        "UnMgDGKiCTft",
        "97AibjK73T03",
        "Gw8Cro-7C8fA",
        "XB1TPaIbDjk4",
        "TCwOcTzk3T04",
        "grVW6mEB3T04",
        "lhxiLE7-3T04",
        "ZkdHIH-NF1R7",
        "2qvvku_FF8Kb",
        "dhdJDLf_3T1A"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}