{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valentinagliozzi/NNCourse/blob/main/LabCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUtPyseJqqlC"
      },
      "source": [
        "# **Convolutional Neural Networks** (CNNs)\n",
        "\n",
        "Here is the translated version with updated links:\n",
        "\n",
        "---\n",
        "\n",
        "**Convolutional Neural Networks (CNNs)** are a type of artificial neural network designed for the efficient processing of data in matrix (or tensor) form, with images being the most common example.\n",
        "\n",
        "These networks have revolutionized the field of image processing and have driven the widespread adoption of deep learning. In many areas, including image analysis, pattern recognition, and computer vision, deep learning  represents the state of the art since 10 years ago.\n",
        "\n",
        "CNNs use **convolutional layers**  to extract features, along with fully connected layers, to solve the task at hand (in our case, *multi-class classification*).\n",
        "\n",
        "![Image](https://mriquestions.com/uploads/3/4/5/7/34572113/cnn-sample-layout_orig.png)\n",
        "\n",
        "#Compared to Multilayer Perceptrons, CNNs are more complex, making it challenging to visualize their structure. However, there are excellent visualizations available online, such as \"[An Interactive Node-Link Visualization of Convolutional Neural Networks](https://adamharley.com/nn_vis/)\" by Adam W. Harley.\n",
        "\n",
        "#![Screenshot interactive node visualization](https://adamharley.com/nn_vis/images/convnet_flat_480.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DbXKIib3T0z"
      },
      "source": [
        "\n",
        "\n",
        "#<font color='lime'><u>**Lab: FashionMNIST Classification with CNN**</u></font>\n",
        "\n",
        "We will use [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), a dataset containing low-resolution images of clothing items, provided by Zalando for classification. It is designed as a more challenging benchmark than [MNIST](https://en.wikipedia.org/wiki/MNIST_database), a well-known dataset containing a large set of images of handwritten digits.\n",
        "\n",
        "For the deep learning framework, we will use **PyTorch**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyvZ9kAN5iLa"
      },
      "source": [
        "### <font color='gold'>**Installing Dependencies and Importing Libraries**</font>\n",
        "\n",
        "Let's install the dependencies and import the necessary libraries.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMga4dM6AVHs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install umap-learn torchviz torchview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy7uKoVRrvVG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# for data visualisation\n",
        "from sklearn.decomposition import PCA\n",
        "from umap import UMAP\n",
        "\n",
        "# for graphs visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch components\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# varia\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from types import SimpleNamespace\n",
        "from torchviz import make_dot\n",
        "from torchview import draw_graph\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XEaQOEy6KmE"
      },
      "source": [
        "### <font color='gold'>**Creazione del dataset**</font>\n",
        "\n",
        "yTorch provides the `FashionMNIST` (`torchvision.datasets`) which encapsulates the dataset as a list of [PIL images](https://pillow.readthedocs.io/en/latest/reference/Image.html). To convert them into tensors, it is sufficient to specify the use of the transformation `torchvision.ToTensor`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Y3NBnDs3_p"
      },
      "outputs": [],
      "source": [
        "dataset = FashionMNIST(\n",
        "    root='data',  # directory  download\n",
        "    download=True,\n",
        "    transform=ToTensor()  # transformation: PIL.image ==> torch.Tensor\n",
        "    )\n",
        "target_names =  ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print('\\n Dataset Information\\n' + '-'*100)\n",
        "print(f'Number of di examples: {len(dataset):,}')\n",
        "print('Number of classes:', len(set(dataset.targets.tolist())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk0LJOyt6tpp"
      },
      "source": [
        "\n",
        "\n",
        "### <font color='gold'>**Partitioning the Dataset: Train, Validation, Test**</font>\n",
        "\n",
        "Using the `torch.utils.data.random_split` function, we randomly divide the dataset into 3 portions:\n",
        "\n",
        "- <u>Training Set</u>  (80%): Contains the data that will be used to train the network.\n",
        "- <u>Test Set</u>  (10%): Contains the data that will be used **only at the end** to test the network's performance.\n",
        "- <u>Validation set</u> (10%): Contains the data that will be used periodically during training to estimate the performance of the network on the test set.\n",
        "‚û°Ô∏è **Note**: The data in the validation set is not used to train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLFr9xHN29dT"
      },
      "outputs": [],
      "source": [
        "seed_random_split = 2023\n",
        "\n",
        "random_generator = torch.Generator().manual_seed(seed_random_split)\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, lengths=[0.8, 0.1, 0.1], generator=random_generator)\n",
        "\n",
        "print('Random split dataset\\n' + '-'*100)\n",
        "print(f'Training set:\\t{len(train_dataset):,}')\n",
        "print(f'Validation set:\\t{len(val_dataset):,}')\n",
        "print(f'Test set:\\t{len(test_dataset):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-uWG8d7yYm"
      },
      "source": [
        "###   <font color='gold'>**Let's Observe Some Information About an Example from the Training Set**</font>\n",
        "\n",
        "We can see that an example is a 3-dimensional tensor, referring respectively to:\n",
        "\n",
        "\n",
        "1. Number of Channels:\n",
        "   - RGB images will have 3 channels.\n",
        "   - RGBA images (A = alpha, opacity) will have 4 channels.\n",
        "   - Grayscale images (our case) will have 1 channel.\n",
        "2. Image Height\n",
        "3. Image Width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9vGxOiBziL_"
      },
      "outputs": [],
      "source": [
        "print('Example n. 1\\n' + '-'*100)\n",
        "x, y = train_dataset[0]\n",
        "print('Input:', x.shape, '\\t ==> (channel, height, width)')\n",
        "print('Classe:', y, f'({target_names[y]})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0mjmvCg8ILf"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Let's Visualize Some Examples (Images)**</font>\n",
        "\n",
        "We can use the `matplotlib.pyplot.imshow` function to visualize the tensors as images. The function maps each value (normalized to the range [0, 1]) to a color. In this case, we invert the value to have black images on a white background.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWg7TIOAx4Pp"
      },
      "outputs": [],
      "source": [
        "plt.subplots(4,4, figsize=(10,10))\n",
        "for i in range(16):\n",
        "  x, y = train_dataset[i]\n",
        "  plt.subplot(4, 4, i+1)\n",
        "  plt.imshow(1-x[0], cmap='gray')\n",
        "  plt.title(target_names[y])\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a2OtcHA8rvi"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Let's Visualize the Distribution of Examples ( Dimensionality Reduction)**</font>\n",
        "\n",
        "When tackling a task, it's good practice to carefully observe the dataset first.\n",
        "\n",
        "We can visualize how separated the classes are by projecting the tensors of the examples into a two-dimensional space and displaying them in a *scatter plot*.\n",
        "\n",
        "We can reduce the tensors corresponding to the examples into pairs of real numbers using a *dimensionality reduction* approach."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Define a *Utility Function* to Visualize the Dataset Using a Given Dimensionality Reduction Method (Compatible with the `Scikit-Learn` Interface)\n"
      ],
      "metadata": {
        "id": "Eq1uY259itV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5fkG8va33d1"
      },
      "outputs": [],
      "source": [
        "def plot_dataset_visualization(X, y, method, title):\n",
        "  X_transformed = method.fit_transform(X)\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  for i, l in enumerate(target_names):\n",
        "    X_plot = X_transformed[y == i]\n",
        "    plt.scatter(X_plot[:,0], X_plot[:,1], label=l, c=f'C{i}', s=1)\n",
        "\n",
        "  plt.legend(markerscale=8, loc=(1.01,0), frameon=False)\n",
        "  plt.title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_wZMdaq89f3"
      },
      "source": [
        "Let's Visualize the Dataset, Coloring Examples of the Same Class with the Same Color, Using Two Different Visualization Methods:\n",
        "\n",
        "- [Principal Component Analisys](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA): PCA performs a linear transformation of the dataset into a space of new, uncorrelated features. Subsequently, the *n* (2 in our case) features that capture the maximum variance are retained.\n",
        "\n",
        "- [Uniform manifold approximation and projection](https://pair-code.github.io/understanding-umap/) (UMAP): A non-linear dimensionality reduction method that produces a result similar to PCA but allows for much clearer visualization of the separation between classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgX0zPAK5GER"
      },
      "outputs": [],
      "source": [
        "X = dataset.data\n",
        "y = dataset.targets\n",
        "X = X.reshape(len(X), -1)\n",
        "\n",
        "\n",
        "visualizers = {\n",
        "    'Principal Component Analysis': PCA(n_components=2),\n",
        "    'Uniform Manifold Approximation and Projection': UMAP(n_components=2, n_epochs=50)\n",
        "}\n",
        "\n",
        "for name, method in visualizers.items():\n",
        "  plot_dataset_visualization(X, y, method, name)\n",
        "  plt.show()\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XGHLTdf3T02"
      },
      "source": [
        "We can observe that the classes are partially overlapping, making the classification problem non-trivial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnMgDGKiCTft"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### <font color='gold'>**Defining the Convolutional Network**</font>\n",
        "\n",
        "In `PyTorch`, to define a network, it is necessary to:\n",
        "\n",
        "- Extend the `torch.nn.Module` class.\n",
        "- Define the layers (or possibly the individual parameters) of the network in the `__init__` function.\n",
        "- Implement the `forward` function, which constitutes the forward pass of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Define the Convolutional Network Using Layers Offered by PyTorch:\n",
        "\n",
        "- `Conv2d` allows us to define convolutions by specifying the input/output channels, kernel size, stride, and padding.\n",
        "- Activation Function `ReLU`: The ReLU (Rectified Linear Unit) activation function introduces non-linearity into the model.\n",
        "- `MaxPool2d` Specifies the kernel size, stride, and padding for max pooling operations.\n",
        "- `BatchNorm2d` *normalizes* and *centers* the layer's input, stabilizing and accelerating training.\n",
        "- `Dropout` Randomly sets some input features of the layer to zero with probability $p$ (only during training). This improves the model's generalization.\n",
        "\n",
        "In the remaining part of the network, we also use:\n",
        "\n",
        "- `Linear`: Defines a single fully connected layer.\n",
        "- As the final layer, `Softmax`: Calculates the probability of belonging to the\n",
        "$i$-th class as follows:\n",
        "\n",
        "\n",
        "$$\\text{softmax}(\\mathbf{x})_i = \\frac{\\exp\\left(x_i\\right)}{\\exp\\left(\\sum_{j=1}^d x_j\\right)}$$"
      ],
      "metadata": {
        "id": "321JQ7VjqsEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_uWqNk3aYPs"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding='valid'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='valid'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Dropout(0.6), # 0.6\n",
        "        nn.Linear(in_features=800, out_features=256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=256, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "    self.out = nn.Sequential(\n",
        "        nn.Linear(in_features=64, out_features=len(target_names)),\n",
        "        nn.Softmax(-1)\n",
        "    )\n",
        "    self.embeddings = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "\n",
        "    # Flatten from dimension 1 onwards\n",
        "    x = x.flatten(1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    # save the vector representation for visualization\n",
        "    self.embeddings = x\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "print('Architecture of the CNN\\n' + '-' * 100)\n",
        "model = CNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97AibjK73T03"
      },
      "source": [
        "### üí°<font color='lightblue'>**In-depth: Visualization with GraphViz of the model and the computational graph**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB65HfmR3T03"
      },
      "source": [
        "There are libraries for visualizing the architecture in the form of a graph. For example, the function `torchview.draw_graph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xi6jRka3T03"
      },
      "outputs": [],
      "source": [
        "x = torch.zeros(10, 1, 28, 28)\n",
        "y = torch.zeros(10)\n",
        "dot = draw_graph(model, input_data=x, expand_nested=True, graph_name='CNN', device='cpu')\n",
        "dot.resize_graph(1.5)\n",
        "dot.visual_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fct2SW-o3T03"
      },
      "source": [
        "Other libraries, such as `torchviz`, allow us to visualize the entire computational graph. For example, let's compute the model output and visualize the graph using the `torchviz.make_dot` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57wEkdnt3T03"
      },
      "outputs": [],
      "source": [
        "pred = model(x)\n",
        "dot = make_dot(pred, params=dict(list(model.named_parameters()) + [('Prediction', pred)]))\n",
        "dot.node_attr.update({'width': '0.1', 'margin': '0.01'})\n",
        "dot.graph_attr.update({'size': '50,50', 'nodesep': '0.2', 'ranksep': '0.25'})\n",
        "dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw8Cro-7C8fA"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Function `evaluate`**</font>\n",
        "\n",
        "Let's define a *utility function* to evaluate the performance of a model on a dataset.\n",
        "The function returns:\n",
        "\n",
        "- <u>Average loss</u> on the dataset\n",
        "- <u>Accuracy</u> of the prediction (assuming the class with the highest probability is selected)\n",
        "- <u>Info</u>: a dictionary containing data that will be useful for studying the training process:\n",
        "  - Embedding (vector representation before the output layer) of the examples\n",
        "  -Probability distribution returned by the model\n",
        "  - Model prediction (most probable class)\n",
        "  -Targets (true labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O06CHdlULayW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataset, args, no_loading_bar=True):\n",
        "  dataloader = DataLoader(dataset, batch_size=args.batch_size, num_workers=2)\n",
        "\n",
        "  tot_loss = 0\n",
        "  n_correct = 0\n",
        "  embeddings, preds, target, probs = [], [], [], []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for (X, y) in tqdm(dataloader, disable=no_loading_bar):\n",
        "      X, y = X.to(args.device), y.to(args.device)\n",
        "\n",
        "      # Calculation of the probabilities of class membership\n",
        "      prob = model(X)\n",
        "\n",
        "      # Calculation of the predictions: class with the highest probability\n",
        "      pred = prob.argmax(-1)\n",
        "\n",
        "      # Calculation of the average loss on the batch (can be Mean Squared Error, Cross Entropy, or other...)\n",
        "      loss = args.loss_fn(prob, y)\n",
        "\n",
        "      n_correct += sum(pred == y)\n",
        "      tot_loss += loss.item() * X.shape[0]\n",
        "\n",
        "      embeddings.append(model.embeddings)\n",
        "      probs.append(prob)\n",
        "      preds.append(pred)\n",
        "      target.append(y)\n",
        "\n",
        "  info = {\n",
        "    'embeddings': torch.cat(embeddings),\n",
        "    'prob': torch.cat(probs),\n",
        "    'preds': torch.cat(preds),\n",
        "    'target': torch.cat(target)\n",
        "  }\n",
        "  return tot_loss / len(dataset), n_correct / len(dataset), info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB1TPaIbDjk4"
      },
      "source": [
        "\n",
        "\n",
        "### <font color='gold'>**Function  `train`**</font>\n",
        "\n",
        "Let's define the actual training function. The function implements an algorithm of [Early stopping](https://en.wikipedia.org/wiki/Early_stopping), a regularization technique that allows training a model to avoid overfitting. This algorithm is based on the concept of *patience*, which is the number of epochs that can pass without the validation loss decreasing before training ends.\n",
        "\n",
        "In other words, early stopping works as follows:\n",
        "\n",
        "\n",
        "1. Consider a parameter `patience`, and a variable `count` (initially set to 0).\n",
        "2. At the end of each epoch, calculate the validation loss.\n",
        "3. If the validation loss is <font color='green'>less than</font> that of the previous epoch, continue training for the next epoch.\n",
        "4. Otherwise, if the loss is <font color='red'>greater than</font> the previous epoch, update count as follows: count = count + 1.\n",
        "5. If `count == patience` (the level of *patience* has been reached), then terminate the training.\n",
        "**Note 1:** <font color=\"aqua\">Why use patience, and not stop when the validation loss decreases?</font>\n",
        "\n",
        "\n",
        "- <u>Overfitting</u> occurs when the training loss continues to decrease but the validation loss starts to increase.\n",
        "- - However, it may not be a good idea to stop training as soon as a lower validation loss is encountered compared to the previous epoch.\n",
        "In fact, it often happens that in some subsequent epoch, the loss decreases again.\n",
        "\n",
        "**Note 2:** <font color='aqua'>Keep track of the best checkpoint (the state of the network weights)</font>\n",
        "\n",
        "- It is a good practice to keep track of the network weights whenever the validation loss improves.\n",
        "- This way, at the end of training, we can obtain the network with the <u>minimum validation loss</u>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwfJlCg0LZ9H"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataset, val_dataset, args):\n",
        "  optimizer = args.optim_class(model.parameters(), lr=args.lr)\n",
        "  dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  train_losses, val_losses = dict(), dict()\n",
        "  step = -1\n",
        "  count = 0\n",
        "  best_val_loss = float('inf')\n",
        "  best_model = None\n",
        "\n",
        "  ### START OF TRAINING\n",
        "  for epoch in range(args.n_epochs):\n",
        "\n",
        "    tot_loss = 0\n",
        "    num_examples = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    loading_bar = tqdm(dataloader)\n",
        "    model.train()\n",
        "\n",
        "    ### EPOCH OF TRAINING\n",
        "    for (X, y) in loading_bar:\n",
        "      X, y = X.to(args.device), y.to(args.device)\n",
        "\n",
        "      # classes probability\n",
        "      prob = model(X)\n",
        "\n",
        "      # average loss on batch\n",
        "      loss = args.loss_fn(prob, y)\n",
        "\n",
        "      # Gradient zeroing, backpropagation, and optimization\n",
        "      # Gradient Zeroing: Before performing a new optimization step, the gradients from the previous step need to be cleared.\n",
        "      # This is done to prevent accumulation of gradients across multiple iterations, which could lead to incorrect updates.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #Backpropagation: This is the process of computing the gradient of the loss function with respect to each weight by the chain rule,\n",
        "      #allowing us to propagate the error backward through the network.\n",
        "      loss.backward()\n",
        "\n",
        "      #After calculating the gradients, an optimizer updates the weights of the model based on these gradients.\n",
        "      optimizer.step()\n",
        "      step += 1\n",
        "\n",
        "      # log step\n",
        "      tot_loss += loss.item() * X.shape[0]\n",
        "      num_examples += X.shape[0]\n",
        "      running_loss = tot_loss / num_examples\n",
        "      train_losses[step] = running_loss\n",
        "\n",
        "      pred = prob.argmax(-1)\n",
        "      n_correct += sum(pred == y)\n",
        "\n",
        "      loading_bar.set_description(f'Epoch {epoch+1:<3d} [Loss: {running_loss:.4f}]')\n",
        "    ### END OF EPOCH OF TRANING\n",
        "\n",
        "    train_accuracy = n_correct / len(train_dataset)\n",
        "    val_loss, val_accuracy, _ = evaluate(model, val_dataset, args)\n",
        "    val_losses[step] = val_loss\n",
        "\n",
        "    print('-'*80)\n",
        "    print(f'Train accuracy: {train_accuracy:.2%}')\n",
        "    print(f'Val accuracy:   {val_accuracy:.2%}')\n",
        "    print(f'Val loss:       {val_loss:.4f}')\n",
        "\n",
        "    # early stopping\n",
        "    if val_loss > best_val_loss:\n",
        "      count += 1\n",
        "      print(f'===> Patience {count:>3d}/{args.patience:<3d}')\n",
        "      if count == args.patience:\n",
        "        break\n",
        "    else:\n",
        "      count = 0\n",
        "      best_val_loss = val_loss\n",
        "      best_model = model.state_dict()\n",
        "\n",
        "    print()\n",
        "  ### END OF TRAINING\n",
        "\n",
        "  model.load_state_dict(best_model)\n",
        "\n",
        "  return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCwOcTzk3T04"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Definition of Training Hyperparameters**</font>\n",
        "\n",
        "Let's define the training hyperparameters. We use **Cross-Entropy Loss**, which is often better than *Mean-Squared Error* in classification problems:\n",
        "$$\n",
        "H_p(q) = - \\sum_{c=1}^Cq(y_c) \\log p(y_c)\n",
        "$$\n",
        "\n",
        "As the optimization algorithm, we use *Adam*, which is often better than the classic *Stochastic Gradient Descent*.\n",
        "\n",
        "We save the weights of the network to perform comparisons with those at the end of training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w_IRj2_-2H8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "9432cc64-c49f-40ab-f288-946d0fe22806"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CNN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f228eb5888da>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_before_train.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
          ]
        }
      ],
      "source": [
        "args = SimpleNamespace(\n",
        "    loss_fn = nn.CrossEntropyLoss(),\n",
        "    optim_class = torch.optim.Adam,\n",
        "    batch_size = 1024,\n",
        "    lr = 0.0005,\n",
        "    n_epochs = 20,\n",
        "    patience = 20,\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "model = CNN().to(args.device)\n",
        "\n",
        "torch.save(model.state_dict(), 'model_before_train.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grVW6mEB3T04"
      },
      "source": [
        "### <font color='gold'>**Training!**</font> üß†\n",
        "\n",
        "We are ready to train the network. <u>**Note:**</u> on **Colab con runtime T4 GPU**, the training takes about <font color='red'>2</font> minutes.\n",
        "\n",
        "We save the model weights after training, along with the training and validation loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAO12UJKuS_D"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = train(model, train_dataset, val_dataset, args)\n",
        "\n",
        "torch.save({'train': train_losses, 'val': val_losses}, 'losses.pt')\n",
        "torch.save(model.state_dict(), 'model_after_train.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhxiLE7-3T04"
      },
      "source": [
        "\n",
        "\n",
        "### üí°<font color='lightblue'>**In-depth: Visualization of the representations learned by the network**</font>\n",
        "\n",
        "We can visualize how the network has learned to represent each example internally.\n",
        "\n",
        "In defining the `forward` function of the network, we programmed the saving of the internal representation of the network before the output layer, as shown here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eZaZp8k3T04"
      },
      "outputs": [],
      "source": [
        "print(model.__repr__().replace('(out)', '\\033[96m>>>>>>>>>>>>>>> SAVE EMBEDDINGS  (INPUT TO OUTPUT LEVEL) <<<<<<<<<<<<<<<\\033[0m\\n  (out)'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D4z0gmF3T05"
      },
      "source": [
        "Let's visualize with PCA the vector representations of each example taken before the portion of the network called `out` (which returns the probabilities of belonging to a class)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUTpLelrwMPu"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('model_before_train.pt'))\n",
        "_, _, info = evaluate(model, train_dataset, args, no_loading_bar=False)\n",
        "plot_dataset_visualization(info['embeddings'].cpu(), info['target'].cpu(), PCA(2), 'Internal Representation before training')\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "model.load_state_dict(torch.load('model_after_train.pt'))\n",
        "_, _, info = evaluate(model, train_dataset, args, no_loading_bar=False)\n",
        "plot_dataset_visualization(info['embeddings'].cpu(), info['target'].cpu(), PCA(2), 'Internal Representation  $\\mathbf{after}$ training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkdHIH-NF1R7"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Visualization of Training Loss and Validation Loss**</font>\n",
        "\n",
        "Now we can visualize the graph of training loss and validation loss. We overlay the two curves to see how they progress during training. We also visualize the curves on a logarithmic scale (over the number of *steps*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUL5108sp5en"
      },
      "outputs": [],
      "source": [
        "losses_dict = torch.load('losses.pt')\n",
        "train_losses, val_losses = losses_dict['train'], losses_dict['val']\n",
        "\n",
        "plt.subplots(1,2, figsize=(16,4))\n",
        "for i, (func, title) in enumerate([(plt.plot, 'Loss'), (plt.semilogx, 'Loss (log scale)')]):\n",
        "  plt.subplot(1,2,i+1)\n",
        "  func(list(train_losses.keys()), list(train_losses.values()), label='Train loss')\n",
        "  func(list(val_losses.keys()), list(val_losses.values()), label='Val loss')\n",
        "  idx = np.argmin(list(val_losses.values()))\n",
        "  plt.axvline(list(val_losses.keys())[idx], color='red', label='Best val loss', linestyle='dashed')\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  plt.subplots_adjust(wspace=0.1)\n",
        "  plt.xlabel('step')\n",
        "  plt.grid('on', 'both')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qvvku_FF8Kb"
      },
      "source": [
        "\n",
        "### <font color='gold'>**Model Testing**</font>\n",
        "\n",
        "Once training is complete, we can test the performance of our model. First, let's calculate the accuracy of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btjy3n3EsJFy"
      },
      "outputs": [],
      "source": [
        "_, test_accuracy, info = evaluate(model, test_dataset, args)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qFxeeXS3T1A"
      },
      "source": [
        "Now let's visualize the confusion matrix to observe the most common errors made by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgZge2l33T1A"
      },
      "outputs": [],
      "source": [
        "target, preds = info['target'].cpu(), info['preds'].cpu()\n",
        "ConfusionMatrixDisplay.from_predictions(target, preds)\n",
        "plt.gca().set_yticklabels(target_names)\n",
        "plt.gca().set_xticklabels(target_names)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdJDLf_3T1A"
      },
      "source": [
        "\n",
        "### üí°<font color='lightblue'>**In-depth: Misclassification of  *Shirts***</font>\n",
        "\n",
        "It can be observed that examples of the *Shirt* class are often misclassified."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage of misclassified examples\\n' + '-'*100)\n",
        "for y in range(len(target_names)):\n",
        "  misclassified_y = (preds != target) & (target == y)\n",
        "  all_y = target == y\n",
        "\n",
        "  print(f'{target_names[y]:>12}: {sum(misclassified_y)/sum(all_y):.2%}')"
      ],
      "metadata": {
        "id": "hu2gKCqzuv0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we are curious, we can take a look at the *Shirts* that were misclassified, and we can inspect the probabilities for each class."
      ],
      "metadata": {
        "id": "eQ5Cc3FhuuqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivSsjTF3T1A"
      },
      "outputs": [],
      "source": [
        "#We filter the \"Shirts\" from the test set that were not classified correctly.\n",
        "misclassified_shirts = (preds != target) & (target == 6)\n",
        "indexes = misclassified_shirts.nonzero().flatten()\n",
        "probs = info['prob'].cpu()[misclassified_shirts]\n",
        "\n",
        "# grid 4 x 3\n",
        "rows, cols = 4, 3\n",
        "fig, _ = plt.subplots(rows, 2 * cols, figsize=(12,10))\n",
        "fig.suptitle(f'Predizioni del modello (true class: {target_names[6]})', y=0.9)\n",
        "\n",
        "for i in range(0, rows * cols * 2, 2):\n",
        "    plt.subplot(rows, 2 * cols, i+1)\n",
        "    x, y = test_dataset[indexes[i]]\n",
        "    plt.imshow(1-x[0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(rows, 2 * cols, i+2)\n",
        "    # Let's print a pie chart of the probabilities greater than 0.01%.\n",
        "    probs_i = np.round(100 * probs[i].numpy(), decimals=2)\n",
        "    patches, _ = plt.pie(probs_i)\n",
        "    patches = [patches[i] for i, p in enumerate(probs_i) if p >= 0.01]\n",
        "    labels = [f'{target_names[i]} - {p:.2f}%' for i, p in enumerate(probs_i) if p >= 0.01]\n",
        "    plt.legend(patches, labels, loc='upper center', fontsize=8, framealpha=0.5)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.01, hspace=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Conclusion\n",
        "Solving a Machine Learning problem almost always requires *trial and error*, especially in the choice of hyperparameters.\n",
        "\n",
        "If you're interested, you can try to improve the model's performance. <font color='gold'><u>**What to modify?**</u></font>\n",
        "\n",
        "1) With the help of the  [PyTorch documentation](https://pytorch.org/docs/stable/nn.html), try varying in the model:\n",
        "* the number of convolutional layers\n",
        "* parameters of convolutional and pooling layers\n",
        "* kernel size\n",
        "* padding\n",
        "* stride\n",
        "* the number of *fully connected* layers (`Linear`) and, in each, the number of neurons\n",
        "* the presence of `Dropout` layers (potentially modifying the *dropout rate*)\n",
        "* the presence of `BatchNorm2d` layers\n",
        "\n",
        "2) Vary the learning hyperparameters:\n",
        "* the maximum number of epochs\n",
        "* the number of epochs to \"patience\"\n",
        "* the size of mini-batches\n",
        "* the learning algorithm (e.g., `SGD`)\n",
        "* learning rate\n",
        "\n",
        "**With this dataset and using a relatively simple convolutional network, the accuracy can easily exceed 90%.**\n"
      ],
      "metadata": {
        "id": "CtXsP7a-DJpL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}